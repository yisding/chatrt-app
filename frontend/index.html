<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>OpenAI Realtime API Voice Agent</title>
    <style>
      :root {
        --bg: #0b1220;
        --fg: #e8eefc;
        --muted: #9fb0d4;
        --accent: #6aa1ff;
        --success: #22c55e;
        --warning: #f59e0b;
      }
      html, body {
        height: 100%;
        margin: 0;
        padding: 0;
      }
      body {
        font-family:
          ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto,
          Helvetica, Arial;
        background: var(--bg);
        color: var(--fg);
        display: flex;
        flex-direction: column;
      }
      .toolbar {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 16px 20px;
        background: rgba(255, 255, 255, 0.04);
        border-bottom: 1px solid rgba(255, 255, 255, 0.08);
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.15);
      }
      .toolbar-left {
        display: flex;
        align-items: center;
        gap: 20px;
      }
      .video-options {
        display: flex;
        align-items: center;
        gap: 16px;
        font-size: 14px;
      }
      .video-option {
        display: flex;
        align-items: center;
        gap: 6px;
      }
      .video-option input[type="radio"] {
        width: 16px;
        height: 16px;
        cursor: pointer;
        margin: 0;
      }
      .video-option label {
        cursor: pointer;
        user-select: none;
      }
      .video-option input[type="radio"]:disabled + label {
        opacity: 0.5;
        cursor: not-allowed;
      }
      .toolbar-right {
        display: flex;
        align-items: center;
        gap: 16px;
      }
      h1 {
        margin: 0;
        font-size: 18px;
        font-weight: 600;
      }
      .status-led {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        background: var(--muted);
        transition: background-color 0.3s ease;
        box-shadow: 0 0 0 2px rgba(255, 255, 255, 0.1);
      }
      .status-led.connected {
        background: var(--success);
        box-shadow:
          0 0 0 2px rgba(34, 197, 94, 0.3),
          0 0 8px rgba(34, 197, 94, 0.4);
      }
      .status-led.connecting {
        background: var(--warning);
        box-shadow:
          0 0 0 2px rgba(245, 158, 11, 0.3),
          0 0 8px rgba(245, 158, 11, 0.4);
        animation: pulse 1.5s infinite;
      }
      @keyframes pulse {
        0%, 100% {
          opacity: 1;
        }
        50% {
          opacity: 0.5;
        }
      }
      .status-text {
        font-size: 13px;
        color: var(--muted);
        min-width: 80px;
      }
      button {
        appearance: none;
        border: 1px solid rgba(255, 255, 255, 0.16);
        background: transparent;
        color: var(--fg);
        padding: 8px 16px;
        border-radius: 8px;
        cursor: pointer;
        font-weight: 600;
        font-size: 14px;
      }
      button.primary {
        background: var(--accent);
        color: #021226;
        border-color: transparent;
      }
      button:disabled {
        opacity: 0.5;
        cursor: not-allowed;
      }
      .logs-container {
        flex: 1;
        display: flex;
        flex-direction: column;
        padding: 20px;
        overflow: hidden;
      }
      .logs-header {
        margin: 0 0 12px 0;
        font-size: 14px;
        color: var(--muted);
        font-weight: 600;
      }
      .logs {
        flex: 1;
        background: rgba(0, 0, 0, 0.35);
        border-radius: 12px;
        border: 1px solid rgba(255, 255, 255, 0.06);
        padding: 16px;
        overflow-y: auto;
        font-family:
          "SF Mono", Monaco, "Cascadia Code", "Roboto Mono", Consolas,
          "Courier New", monospace;
        font-size: 13px;
        line-height: 1.4;
        white-space: pre-wrap;
      }
      .screen-preview {
        display: none;
        width: 100%;
        max-width: 100%;
        margin-bottom: 20px;
        border-radius: 12px;
        border: 1px solid rgba(255, 255, 255, 0.06);
        background: rgba(0, 0, 0, 0.35);
        overflow: hidden;
      }
      .screen-preview.active {
        display: block;
      }
      .screen-preview video {
        width: 100%;
        height: auto;
        display: block;
        max-height: 400px;
        object-fit: contain;
        background: #000;
      }
      .log-entry {
        margin-bottom: 4px;
      }
      .log-timestamp {
        color: var(--muted);
        opacity: 0.7;
      }
      .log-message {
        color: var(--fg);
      }
      audio {
        display: none;
      }
    </style>
  </head>
  <body>
    <div class="toolbar">
      <div class="toolbar-left">
        <h1>Realtime Agent</h1>
        <button id="btnStart" class="primary">Start</button>
        <div class="video-options">
          <div class="video-option">
            <input
              type="radio"
              id="videoNone"
              name="videoMode"
              value="none"
              checked
            />
            <label for="videoNone">Audio Only</label>
          </div>
          <div class="video-option">
            <input
              type="radio"
              id="videoScreen"
              name="videoMode"
              value="screen"
            />
            <label for="videoScreen">Screen</label>
          </div>
          <div class="video-option">
            <input
              type="radio"
              id="videoWebcam"
              name="videoMode"
              value="webcam"
            />
            <label for="videoWebcam">Webcam</label>
          </div>
        </div>
      </div>
      <div class="toolbar-right">
        <span class="status-text" id="statusText">Disconnected</span>
        <div class="status-led" id="statusLed"></div>
      </div>
    </div>

    <div class="logs-container">
      <div class="screen-preview" id="screenPreview">
        <video id="screenVideo" autoplay playsinline muted></video>
      </div>
      <div class="logs" id="logs"></div>
    </div>

    <audio id="remoteAudio" autoplay playsinline></audio>

    <script>
      const $ = (id) => document.getElementById(id);
      const logsEl = $("logs");
      const statusTextEl = $("statusText");
      const statusLedEl = $("statusLed");
      const audioEl = $("remoteAudio");
      const btnStart = $("btnStart");
      const screenPreviewEl = $("screenPreview");
      const screenVideoEl = $("screenVideo");

      let pc = null;
      let localStream = null;
      let videoStream = null;
      let isConnected = false;
      let callStartTime = null;

      function getVideoMode() {
        const selected = document.querySelector(
          'input[name="videoMode"]:checked',
        );
        return selected ? selected.value : "none";
      }

      function disableVideoOptions() {
        document.querySelectorAll('input[name="videoMode"]').forEach(
          (input) => {
            input.disabled = true;
          },
        );
      }

      function enableVideoOptions() {
        document.querySelectorAll('input[name="videoMode"]').forEach(
          (input) => {
            input.disabled = false;
          },
        );
      }

      function formatTimestamp() {
        if (!callStartTime) {
          return "00:00.000";
        }

        const elapsed = Date.now() - callStartTime;
        const minutes = Math.floor(elapsed / 60000);
        const seconds = Math.floor((elapsed % 60000) / 1000);
        const millis = elapsed % 1000;

        return `${minutes.toString().padStart(2, "0")}:${
          seconds.toString().padStart(2, "0")
        }.${millis.toString().padStart(3, "0")}`;
      }

      function log(...args) {
        const timestamp = formatTimestamp();
        const message = args.map(
          (a) => (typeof a === "string" ? a : JSON.stringify(a)),
        ).join(" ");

        const logEntry = document.createElement("div");
        logEntry.className = "log-entry";
        logEntry.innerHTML =
          `<span class="log-timestamp">[${timestamp}]</span> <span class="log-message">${message}</span>`;

        logsEl.appendChild(logEntry);
        logsEl.scrollTop = logsEl.scrollHeight;
        console.log(`[${timestamp}]`, ...args);
      }

      function setStatus(status, ledState = "disconnected") {
        statusTextEl.textContent = status;
        statusLedEl.className = `status-led ${ledState}`;

        if (ledState === "connected") {
          isConnected = true;
          btnStart.textContent = "Stop";
          btnStart.disabled = false;
          disableVideoOptions();
        } else if (ledState === "connecting") {
          isConnected = false;
          btnStart.textContent = "Start";
          btnStart.disabled = true;
          disableVideoOptions();
        } else {
          isConnected = false;
          btnStart.textContent = "Start";
          btnStart.disabled = false;
          enableVideoOptions();
        }
      }

      async function start() {
        if (pc) {
          // If already connected, this is a stop action
          await stop();
          return;
        }

        // Initialize call start time and clear logs
        callStartTime = Date.now();
        logsEl.innerHTML = "";

        setStatus("Initializing...", "connecting");
        log("Starting voice agent connection");
        audioEl.play();

        // 1) Get mic (and optionally webcam) with user-selected constraints
        const videoMode = getVideoMode();
        const constraints = {
          audio: true,
          video: videoMode === "webcam" ? true : false,
        };
        try {
          localStream = await navigator.mediaDevices.getUserMedia(
            constraints,
          );
          log(
            videoMode === "webcam"
              ? "Microphone and webcam access granted"
              : "Microphone access granted",
          );

          // Show webcam preview if using webcam
          if (videoMode === "webcam") {
            screenVideoEl.srcObject = localStream;
            screenPreviewEl.classList.add("active");
          }
        } catch (e) {
          setStatus(
            videoMode === "webcam"
              ? "Microphone/webcam denied"
              : "Microphone denied",
            "disconnected",
          );
          log("getUserMedia error:", e.message || e);
          if (videoMode === "webcam") {
            // Reset to audio only on failure
            document.getElementById("videoNone").checked = true;
          }
          return;
        }

        // 2) Create RTCPeerConnection
        pc = new RTCPeerConnection({});
        pc.onconnectionstatechange = () => {
          log("Connection state:", pc.connectionState);
          if (pc.connectionState === "connected") {
            setStatus("Connected", "connected");
          } else if (pc.connectionState === "failed") {
            setStatus("Connection failed", "failed");
          } else if (pc.connectionState === "disconnected") {
            setStatus("Connection interrupted", "disconnected");
          }
        };

        // 3) Set up remote audio
        pc.ontrack = (ev) => {
          if (ev.track.kind === "audio") {
            log("Received remote audio track");
            audioEl.srcObject = ev.streams[0] ||
              new MediaStream([ev.track]);
          }
        };

        // 4) Add mic track(s) and webcam if selected
        localStream.getTracks().forEach((t) =>
          pc.addTrack(t, localStream)
        );
        if (videoMode === "webcam") {
          log("Added local audio and webcam tracks");
        } else {
          log("Added local audio track");
        }

        // 4b) Add screen capture if selected
        if (videoMode === "screen") {
          try {
            videoStream = await navigator.mediaDevices.getDisplayMedia(
              {
                video: true,
                audio: false,
              },
            );
            videoStream.getTracks().forEach((t) =>
              pc.addTrack(t, videoStream)
            );
            log("Added screen capture video track");

            // Show screen preview
            screenVideoEl.srcObject = videoStream;
            screenPreviewEl.classList.add("active");

            // Handle screen share ending
            videoStream.getVideoTracks()[0].onended = () => {
              log("Screen sharing stopped");
              screenVideoEl.srcObject = null;
              screenPreviewEl.classList.remove("active");
              videoStream = null;
            };
          } catch (e) {
            log("Screen capture denied or failed:", e.message || e);
            // Reset to audio only on failure
            document.getElementById("videoNone").checked = true;
          }
        }

        // 5) Create Offer and send immediately
        log("Creating offer and connecting to server...");
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        // 6) POST SDP offer to /rtc immediately (WHIP-style).
        // Server will provide the session configuration.
        try {
          const resp = await fetch("/rtc", {
            method: "POST",
            headers: { "Content-Type": "application/sdp" },
            body: offer.sdp,
          });

          if (!resp.ok) {
            const errText = await resp.text().catch(() => "<no body>");
            throw new Error(`Server error: ${resp.status} ${errText}`);
          }

          const answerSdp = await resp.text();
          await pc.setRemoteDescription({
            type: "answer",
            sdp: answerSdp,
          });
        } catch (error) {
          log("Connection failed:", error.message);
          setStatus("Connection failed", "disconnected");
          await stop();
        }
      }

      async function stop() {
        log("Stopping voice agent connection");
        setStatus("Disconnecting...", "connecting");

        try {
          if (pc) {
            pc.getSenders().forEach((s) => {
              try {
                s.track && s.track.stop();
              } catch {}
            });
            pc.getReceivers().forEach((r) => {
              try {
                r.track && r.track.stop();
              } catch {}
            });
            pc.ontrack = null;
            pc.close();
          }
        } finally {
          pc = null;
        }

        if (localStream) {
          localStream.getTracks().forEach((t) => {
            try {
              t.stop();
            } catch {}
          });
          localStream = null;
        }

        if (videoStream) {
          videoStream.getTracks().forEach((t) => {
            try {
              t.stop();
            } catch {}
          });
          videoStream = null;
        }

        // Clear video preview regardless of source
        screenVideoEl.srcObject = null;
        screenPreviewEl.classList.remove("active");

        audioEl.srcObject = null;
        setStatus("Disconnected", "disconnected");
        log("Connection stopped");

        // Reset call timer
        callStartTime = null;
      }

      btnStart.addEventListener("click", start);

      // Close gracefully on unload
      window.addEventListener("beforeunload", stop);

      // Initialize
      log("Voice agent interface loaded");
      setStatus("Disconnected", "disconnected");
    </script>
  </body>
</html>
